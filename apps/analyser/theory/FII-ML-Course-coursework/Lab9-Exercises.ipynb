{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "AdaBoost on a uni-dimensional array\n",
    "\n",
    "Given the dataset below and the AdaBoost algorithm using the usual decision stumps as weak learners:\n",
    "\n",
    "1. Plot the dataset using `pyplot`.\n",
    "2. Draw the decision surface corresponding to the first weak learner.\n",
    "3. What are the values of $\\epsilon_1$ (training error of the first decision stump) and $\\alpha_1$ (the \"weight\" of the vode of the first decision stump)?\n",
    "4. What will be the updated weights of the training instances, after the first update?\n",
    "5. Draw the decision surface after adding the second weak learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.DataFrame({\n",
    "    'X': [-1, -0.7, -0.4, -0.1, 0.2, 0.5, 0.8],\n",
    "    'Y': [1, 1, 1, -1, -1, -1, 1]\n",
    "})\n",
    "X, Y = d[['X']], d['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "AdaBoost on a two-dimensional array\n",
    "\n",
    "Given the dataset below and the AdaBoost algorithm using the usual decision stumps as weak learners:\n",
    "1. Plot the dataset using `pyplot`.\n",
    "2. Draw the decision surface corresponding to the first weak learner as chosen by `AdaBoostClassifier` with the default `base_estimator`.\n",
    "3. Show why AdaBoost chose that learner, by plotting the decision surface of all the candidates and their corresponding error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.DataFrame({\n",
    "    'X1': [1, 2, 2.75, 3.25, 4, 5],\n",
    "    'X2': [1, 2, 1.25, 2.75, 2.25, 3.5],\n",
    "    'Y': [1, 1, -1, 1, -1, -1]\n",
    "})\n",
    "X, Y = d[['X1', 'X2']], d['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "AdaBoost vs ID3\n",
    "\n",
    "Given the dataset below:\n",
    "1. Plot the dataset using `pyplot`.\n",
    "2. Compare the training error of the AdaBoost algorithm (using the usual decision stumps as weak learners) and the ID3 algorithm.\n",
    "2. Compare the CVLOO error of the AdaBoost algorithm (using the usual decision stumps as weak learners) and the ID3 algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "x_red = norm.rvs(0, 1, 100, random_state=1)\n",
    "y_red = norm.rvs(0, 1, 100, random_state=2)\n",
    "x_green = norm.rvs(1, 1, 100, random_state=3)\n",
    "y_green = norm.rvs(1, 1, 100, random_state=4)\n",
    "d = pd.DataFrame({\n",
    "    'X1': np.concatenate([x_red,x_green]),\n",
    "    'X2': np.concatenate([y_red,y_green]),\n",
    "    'Y': [1]*100+[0]*100\n",
    "})\n",
    "X, Y = d[['X1', 'X2']], d['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Finding the optimum number of weak learners\n",
    "\n",
    "For the dataset below:\n",
    "1. plot the points using `pyplot.scatter`;\n",
    "1. plot a line chart using `pyplot.plot` that shows the training error and the CVLOO error of AdaBoost using between 1 and 15 weak learners.\n",
    "1. What is the best number of weak learners in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "x_red = norm.rvs(0, 1, 100, random_state=1)\n",
    "y_red = norm.rvs(0, 1, 100, random_state=2)\n",
    "x_green = norm.rvs(1, 1, 100, random_state=3)\n",
    "y_green = norm.rvs(1, 1, 100, random_state=4)\n",
    "d = pd.DataFrame({\n",
    "    'X1': np.concatenate([x_red,x_green]),\n",
    "    'X2': np.concatenate([y_red,y_green]),\n",
    "    'Y': [1]*100+[0]*100\n",
    "})\n",
    "X, Y = d[['X1', 'X2']], d['Y']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
